#!/usr/bin/env python3
"""
æ”¹è¿›çš„æ•°æ®æ›´æ–°è„šæœ¬ - è¡¥é½åˆ†æè¡¨æ•°æ®
åŸºäºç°æœ‰çš„hotdog2030æ•°æ®åº“æ•°æ®ï¼Œå¡«å……æ‰€æœ‰åˆ†æå±‚è¡¨
"""

import os
import pyodbc
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# æ•°æ®åº“è¿æ¥é…ç½®
def get_conn(db_name="hotdog2030"):
    """è·å–æ•°æ®åº“è¿æ¥"""
    conn_str = (
        "DRIVER={ODBC Driver 18 for SQL Server};"
        f"SERVER={os.getenv('MSSQL_HOST', 'rm-uf660d00xovkm3067.sqlserver.rds.aliyuncs.com')},{os.getenv('MSSQL_PORT','1433')};"
        f"DATABASE={db_name};UID={os.getenv('MSSQL_USER','hotdog')};PWD={os.getenv('MSSQL_PASS','Zhkj@62102218')};"
        "TrustServerCertificate=yes;"
    )
    return pyodbc.connect(conn_str)

def execute_sql(sql, params=None):
    """æ‰§è¡ŒSQLè¯­å¥"""
    try:
        with get_conn() as conn:
            cursor = conn.cursor()
            if params:
                cursor.execute(sql, params)
            else:
                cursor.execute(sql)
            conn.commit()
            return True
    except Exception as e:
        logger.error(f"SQLæ‰§è¡Œå¤±è´¥: {e}")
        return False

def fetch_data(sql, params=None):
    """è·å–æ•°æ®"""
    try:
        with get_conn() as conn:
            return pd.read_sql(sql, conn, params=params)
    except Exception as e:
        logger.error(f"æ•°æ®è·å–å¤±è´¥: {e}")
        return pd.DataFrame()

def update_profit_analysis():
    """æ›´æ–°åˆ©æ¶¦åˆ†ææ•°æ®"""
    logger.info("ğŸ”„ å¼€å§‹æ›´æ–°åˆ©æ¶¦åˆ†ææ•°æ®...")
    
    # è®¡ç®—æ¯æ—¥åˆ©æ¶¦æ•°æ®
    sql = """
    INSERT INTO dbo.fact_profit_daily (date_key, store_id, revenue, cogs, operating_exp)
    SELECT 
        CONVERT(int, FORMAT(o.created_at, 'yyyyMMdd')) AS date_key,
        o.store_id,
        SUM(o.total_amount) AS revenue,
        SUM(ISNULL(oi.quantity * ISNULL(p.cost_price, 0), 0)) AS cogs,
        0 AS operating_exp
    FROM dbo.orders o
    LEFT JOIN dbo.order_items oi ON oi.order_id = o.id
    LEFT JOIN dbo.products p ON p.id = oi.product_id
    WHERE o.created_at IS NOT NULL
    GROUP BY CONVERT(int, FORMAT(o.created_at, 'yyyyMMdd')), o.store_id
    """
    
    if execute_sql(sql):
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        count_sql = "SELECT COUNT(*) FROM dbo.fact_profit_daily"
        with get_conn() as conn:
            cursor = conn.cursor()
            cursor.execute(count_sql)
            count = cursor.fetchone()[0]
        logger.info(f"âœ… åˆ©æ¶¦åˆ†ææ•°æ®æ›´æ–°å®Œæˆ: {count:,} æ¡è®°å½•")
        return True
    return False

def update_customer_segmentation():
    """æ›´æ–°å®¢æˆ·åˆ†ç¾¤æ•°æ®"""
    logger.info("ğŸ”„ å¼€å§‹æ›´æ–°å®¢æˆ·åˆ†ç¾¤æ•°æ®...")
    
    # è®¡ç®—RFMæ•°æ®
    sql = """
    WITH customer_rfm AS (
        SELECT 
            o.customer_id,
            DATEDIFF(day, MAX(o.created_at), GETDATE()) AS recency_days,
            COUNT(*) AS frequency,
            SUM(o.total_amount) AS monetary
        FROM dbo.orders o
        WHERE o.customer_id IS NOT NULL AND o.customer_id != ''
        GROUP BY o.customer_id
    ),
    rfm_scores AS (
        SELECT 
            customer_id,
            recency_days,
            frequency,
            monetary,
            CASE 
                WHEN recency_days <= 30 THEN 5
                WHEN recency_days <= 60 THEN 4
                WHEN recency_days <= 90 THEN 3
                WHEN recency_days <= 180 THEN 2
                ELSE 1
            END AS r_score,
            CASE 
                WHEN frequency >= 20 THEN 5
                WHEN frequency >= 10 THEN 4
                WHEN frequency >= 5 THEN 3
                WHEN frequency >= 2 THEN 2
                ELSE 1
            END AS f_score,
            CASE 
                WHEN monetary >= 1000 THEN 5
                WHEN monetary >= 500 THEN 4
                WHEN monetary >= 200 THEN 3
                WHEN monetary >= 100 THEN 2
                ELSE 1
            END AS m_score
        FROM customer_rfm
    )
    INSERT INTO dbo.dim_customer_segment (customer_id, r_score, f_score, m_score, segment_code)
    SELECT 
        customer_id,
        r_score,
        f_score,
        m_score,
        r_score * 100 + f_score * 10 + m_score AS segment_code
    FROM rfm_scores
    """
    
    if execute_sql(sql):
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        count_sql = "SELECT COUNT(*) FROM dbo.dim_customer_segment"
        with get_conn() as conn:
            cursor = conn.cursor()
            cursor.execute(count_sql)
            count = cursor.fetchone()[0]
        logger.info(f"âœ… å®¢æˆ·åˆ†ç¾¤æ•°æ®æ›´æ–°å®Œæˆ: {count:,} æ¡è®°å½•")
        return True
    return False

def update_sales_forecast():
    """æ›´æ–°é”€å”®é¢„æµ‹æ•°æ®"""
    logger.info("ğŸ”„ å¼€å§‹æ›´æ–°é”€å”®é¢„æµ‹æ•°æ®...")
    
    # è·å–å†å²é”€å”®æ•°æ®
    sql = """
    SELECT 
        CONVERT(int, FORMAT(o.created_at, 'yyyyMMdd')) AS date_key,
        o.store_id,
        SUM(o.total_amount) AS revenue
    FROM dbo.orders o
    WHERE o.created_at IS NOT NULL
    GROUP BY CONVERT(int, FORMAT(o.created_at, 'yyyyMMdd')), o.store_id
    ORDER BY o.store_id, date_key
    """
    
    df = fetch_data(sql)
    if df.empty:
        logger.warning("âš ï¸ æ²¡æœ‰å†å²é”€å”®æ•°æ®ç”¨äºé¢„æµ‹")
        return False
    
    # ä¸ºæ¯ä¸ªé—¨åº—ç”Ÿæˆæœªæ¥7å¤©çš„é¢„æµ‹
    predictions = []
    for store_id in df['store_id'].unique():
        store_data = df[df['store_id'] == store_id].sort_values('date_key')
        if len(store_data) < 7:
            continue
            
        # ç®€å•çš„ç§»åŠ¨å¹³å‡é¢„æµ‹
        recent_revenue = store_data['revenue'].tail(7).mean()
        
        # ç”Ÿæˆæœªæ¥7å¤©çš„é¢„æµ‹
        last_date = datetime.strptime(str(store_data['date_key'].iloc[-1]), '%Y%m%d')
        for i in range(1, 8):
            future_date = last_date + timedelta(days=i)
            future_date_key = int(future_date.strftime('%Y%m%d'))
            
            # æ·»åŠ ä¸€äº›éšæœºæ³¢åŠ¨
            variation = np.random.normal(0, 0.1)
            predicted_revenue = recent_revenue * (1 + variation)
            
            predictions.append({
                'date_key': future_date_key,
                'store_id': store_id,
                'yhat': max(0, predicted_revenue),
                'model_name': 'simple_ma'
            })
    
    # æ’å…¥é¢„æµ‹æ•°æ®
    if predictions:
        insert_sql = """
        INSERT INTO dbo.fact_forecast_daily (date_key, store_id, yhat, model_name)
        VALUES (?, ?, ?, ?)
        """
        
        with get_conn() as conn:
            cursor = conn.cursor()
            for pred in predictions:
                cursor.execute(insert_sql, (
                    int(pred['date_key']),
                    int(pred['store_id']),
                    float(pred['yhat']),
                    str(pred['model_name'])
                ))
            conn.commit()
        
        logger.info(f"âœ… é”€å”®é¢„æµ‹æ•°æ®æ›´æ–°å®Œæˆ: {len(predictions):,} æ¡è®°å½•")
        return True
    return False

def update_site_selection():
    """æ›´æ–°é€‰å€è¯„åˆ†æ•°æ®"""
    logger.info("ğŸ”„ å¼€å§‹æ›´æ–°é€‰å€è¯„åˆ†æ•°æ®...")
    
    # è·å–é—¨åº—æ•°æ®ä½œä¸ºå€™é€‰ä½ç½®
    sql = """
    SELECT 
        s.id AS candidate_id,
        s.city,
        s.district AS biz_area,
        AVG(sd.revenue) AS avg_revenue,
        COUNT(DISTINCT s.id) AS store_count
    FROM dbo.stores s
    LEFT JOIN dbo.vw_sales_store_daily sd ON sd.store_id = s.id
    GROUP BY s.id, s.city, s.district
    """
    
    df = fetch_data(sql)
    if df.empty:
        logger.warning("âš ï¸ æ²¡æœ‰é—¨åº—æ•°æ®ç”¨äºé€‰å€åˆ†æ")
        return False
    
    # è®¡ç®—è¯„åˆ†
    df['match_score'] = (df['avg_revenue'] / df['avg_revenue'].max()).fillna(0)
    df['cannibal_score'] = (df['store_count'] / df['store_count'].max()).fillna(0)
    df['total_score'] = 0.6 * df['match_score'] + 0.4 * (1 - df['cannibal_score'])
    df['rationale'] = "åŸºäºå†å²è¥æ”¶å’Œé—¨åº—å¯†åº¦çš„ç»¼åˆè¯„åˆ†"
    
    # æ’å…¥æ•°æ®
    insert_sql = """
    INSERT INTO dbo.fact_site_score (candidate_id, city, biz_area, match_score, cannibal_score, total_score, rationale)
    VALUES (?, ?, ?, ?, ?, ?, ?)
    """
    
    with get_conn() as conn:
        cursor = conn.cursor()
        for _, row in df.iterrows():
            cursor.execute(insert_sql, (
                int(row['candidate_id']),
                str(row['city']),
                str(row['biz_area']),
                float(row['match_score']),
                float(row['cannibal_score']),
                float(row['total_score']),
                str(row['rationale'])
            ))
        conn.commit()
    
    logger.info(f"âœ… é€‰å€è¯„åˆ†æ•°æ®æ›´æ–°å®Œæˆ: {len(df):,} æ¡è®°å½•")
    return True

def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹æ›´æ–°åˆ†æå±‚æ•°æ®...")
    
    # è®¾ç½®ç¯å¢ƒå˜é‡ - ä½¿ç”¨RDS
    os.environ['MSSQL_HOST'] = 'rm-uf660d00xovkm3067.sqlserver.rds.aliyuncs.com'
    os.environ['MSSQL_PORT'] = '1433'
    os.environ['MSSQL_USER'] = 'hotdog'
    os.environ['MSSQL_PASS'] = 'Zhkj@62102218'
    
    # æµ‹è¯•æ•°æ®åº“è¿æ¥
    try:
        with get_conn() as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT 1")
            logger.info("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        return
    
    # æ‰§è¡Œå„ä¸ªæ›´æ–°æ­¥éª¤
    steps = [
        ("åˆ©æ¶¦åˆ†æ", update_profit_analysis),
        ("å®¢æˆ·åˆ†ç¾¤", update_customer_segmentation),
        ("é”€å”®é¢„æµ‹", update_sales_forecast),
        ("é€‰å€è¯„åˆ†", update_site_selection),
    ]
    
    success_count = 0
    for step_name, step_func in steps:
        logger.info(f"ğŸ“‹ æ‰§è¡Œæ­¥éª¤: {step_name}")
        if step_func():
            success_count += 1
        else:
            logger.warning(f"âš ï¸ æ­¥éª¤å¤±è´¥: {step_name}")
    
    # æœ€ç»ˆç»Ÿè®¡
    logger.info("ğŸ‰ æ•°æ®æ›´æ–°å®Œæˆ!")
    logger.info(f"ğŸ“Š æˆåŠŸæ­¥éª¤: {success_count}/{len(steps)}")
    
    # æ˜¾ç¤ºæœ€ç»ˆæ•°æ®ç»Ÿè®¡
    logger.info("\n=== æœ€ç»ˆæ•°æ®ç»Ÿè®¡ ===")
    analysis_tables = ['fact_profit_daily', 'dim_customer_segment', 'fact_forecast_daily', 'fact_site_score']
    for table in analysis_tables:
        try:
            with get_conn() as conn:
                cursor = conn.cursor()
                cursor.execute(f"SELECT COUNT(*) FROM dbo.{table}")
                count = cursor.fetchone()[0]
                logger.info(f"{table}: {count:,} æ¡è®°å½•")
        except Exception as e:
            logger.error(f"{table}: æŸ¥è¯¢å¤±è´¥ - {e}")

if __name__ == "__main__":
    main()