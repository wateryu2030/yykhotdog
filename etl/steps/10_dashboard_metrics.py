"""
ETLæ­¥éª¤10: ä»ªè¡¨æ¿æŒ‡æ ‡èšåˆ
åŸºäºOpenAIå»ºè®®çš„ä¼˜åŒ–ç‰ˆæœ¬
"""
import sys
import os
import pandas as pd
import numpy as np
import datetime as dt
from pathlib import Path

# æ·»åŠ libè·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))
from lib.mssql import fetch_df, to_sql, get_conn, get_table_count, execute_sql
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

DW = "hotdog2030"

def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹ETLæ­¥éª¤10: ä»ªè¡¨æ¿æŒ‡æ ‡èšåˆ")
    
    try:
        # ä» hotdog2030.orders, hotdog2030.stores, hotdog2030.customers è·å–æ•°æ®
        orders_df = fetch_df("SELECT id, store_id, customer_id, total_amount, created_at FROM orders", DW)
        stores_df = fetch_df("SELECT id, store_name, city, province, district FROM stores", DW)
        customers_df = fetch_df("SELECT id, customer_id FROM customers", DW)
        
        if orders_df.empty or stores_df.empty:
            logger.warning("âš ï¸ æ²¡æœ‰è¶³å¤Ÿæ•°æ®ç”Ÿæˆä»ªè¡¨æ¿æŒ‡æ ‡")
            return
        
        orders_df['created_at'] = pd.to_datetime(orders_df['created_at'])
        orders_df['order_date'] = orders_df['created_at'].dt.date
        
        # åˆå¹¶è®¢å•å’Œé—¨åº—ä¿¡æ¯
        df = pd.merge(orders_df, stores_df, left_on='store_id', right_on='id', suffixes=('_order', '_store'))
        
        # è®¡ç®—æ¯æ—¥/æ¯æœˆ/æ¯åº—/æ¯åŸKPI
        # ç¤ºä¾‹ï¼šæ¯æ—¥æ€»é”€å”®é¢ã€è®¢å•æ•°ã€å¹³å‡å®¢å•ä»·
        daily_metrics = df.groupby('order_date').agg(
            total_revenue=('total_amount', 'sum'),
            total_orders=('id_order', 'count'),
            avg_order_value=('total_amount', 'mean')
        ).reset_index()
        
        # ç¤ºä¾‹ï¼šæ¯åº—æ€»é”€å”®é¢ã€è®¢å•æ•°ã€å®¢æˆ·æ•°
        store_metrics = df.groupby(['store_id', 'store_name', 'city', 'district']).agg(
            total_revenue=('total_amount', 'sum'),
            total_orders=('id_order', 'count'),
            unique_customers=('customer_id', lambda x: x.nunique() if x.name == 'customer_id' else pd.NA)
        ).reset_index()
        # ç¡®ä¿ unique_customers åˆ—æ˜¯æ•°å€¼ç±»å‹
        store_metrics['unique_customers'] = pd.to_numeric(store_metrics['unique_customers'], errors='coerce').fillna(0).astype(int)
        
        # ç¤ºä¾‹ï¼šæ¯åŸæ€»é”€å”®é¢ã€è®¢å•æ•°ã€å®¢æˆ·æ•°
        city_metrics = df.groupby(['city', 'province']).agg(
            total_revenue=('total_amount', 'sum'),
            total_orders=('id_order', 'count'),
            unique_customers=('customer_id', lambda x: x.nunique() if x.name == 'customer_id' else pd.NA)
        ).reset_index()
        city_metrics['unique_customers'] = pd.to_numeric(city_metrics['unique_customers'], errors='coerce').fillna(0).astype(int)
        
        # å†™å…¥æ•°æ®åº“
        logger.info("ğŸ’¾ å¼€å§‹å†™å…¥ä»ªè¡¨æ¿æŒ‡æ ‡...")
        
        # å†™å…¥æ¯æ—¥æŒ‡æ ‡
        if not daily_metrics.empty:
            success = to_sql(daily_metrics, "ddashboard_daily_metrics", DW, if_exists='append')
            if success:
                count = get_table_count(DW, "dashboard_daily_metrics")
                logger.info(f"âœ… æ¯æ—¥æŒ‡æ ‡å†™å…¥å®Œæˆ: {count} æ¡è®°å½•")
        
        # å†™å…¥é—¨åº—æŒ‡æ ‡
        if not store_metrics.empty:
            success = to_sql(store_metrics, "ddashboard_store_metrics", DW, if_exists='append')
            if success:
                count = get_table_count(DW, "dashboard_store_metrics")
                logger.info(f"âœ… é—¨åº—æŒ‡æ ‡å†™å…¥å®Œæˆ: {count} æ¡è®°å½•")
        
        # å†™å…¥åŸå¸‚æŒ‡æ ‡
        if not city_metrics.empty:
            success = to_sql(city_metrics, "ddashboard_city_metrics", DW, if_exists='append')
            if success:
                count = get_table_count(DW, "dashboard_city_metrics")
                logger.info(f"âœ… åŸå¸‚æŒ‡æ ‡å†™å…¥å®Œæˆ: {count} æ¡è®°å½•")
        
        logger.info("ğŸ‰ ETLæ­¥éª¤10å®Œæˆ! ä»ªè¡¨æ¿æŒ‡æ ‡èšåˆå®Œæˆ")
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        logger.info(f"ğŸ“Š ä»ªè¡¨æ¿æŒ‡æ ‡ç»Ÿè®¡:")
        logger.info(f"   - æ¯æ—¥æŒ‡æ ‡: {len(daily_metrics)} æ¡")
        logger.info(f"   - é—¨åº—æŒ‡æ ‡: {len(store_metrics)} æ¡")
        logger.info(f"   - åŸå¸‚æŒ‡æ ‡: {len(city_metrics)} æ¡")
        
        if not city_metrics.empty:
            top_city = city_metrics.iloc[0]
            logger.info(f"   - æœ€ä½³åŸå¸‚: {top_city['city']} (æ”¶å…¥: {top_city['total_revenue']:.2f})")
        
        if not store_metrics.empty:
            top_store = store_metrics.iloc[0]
            logger.info(f"   - æœ€ä½³é—¨åº—: {top_store['store_name']} (æ”¶å…¥: {top_store['total_revenue']:.2f})")
            
    except Exception as e:
        logger.error(f"âŒ ETLæ­¥éª¤10æ‰§è¡Œå¤±è´¥: {str(e)}")
        raise

if __name__ == "__main__":
    main()