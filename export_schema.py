#!/usr/bin/env python3
"""
å¯¼å‡ºæ•°æ®åº“ç»“æ„ï¼ˆSchemaï¼‰è„šæœ¬
åªå¯¼å‡ºè¡¨ç»“æ„ï¼Œä¸åŒ…å«æ•°æ®
"""
import pyodbc
import logging
from datetime import datetime

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# æ•°æ®åº“è¿æ¥é…ç½®
DB_CONFIG = {
    'server': 'localhost',
    'port': 1433,
    'username': 'sa',
    'password': 'YourStrong@Passw0rd',
    'driver': '{ODBC Driver 18 for SQL Server}',
    'timeout': 30
}

def get_connection(database):
    """è·å–æ•°æ®åº“è¿æ¥"""
    conn_str = (
        f"DRIVER={DB_CONFIG['driver']};"
        f"SERVER={DB_CONFIG['server']},{DB_CONFIG['port']};"
        f"DATABASE={database};"
        f"UID={DB_CONFIG['username']};"
        f"PWD={DB_CONFIG['password']};"
        f"Encrypt=no;"
        f"TrustServerCertificate=yes;"
        f"Connection Timeout={DB_CONFIG['timeout']}"
    )
    try:
        conn = pyodbc.connect(conn_str, autocommit=True)
        logger.info(f"âœ… è¿æ¥åˆ° {database} æ•°æ®åº“æˆåŠŸ")
        return conn
    except Exception as e:
        logger.error(f"âŒ è¿æ¥ {database} æ•°æ®åº“å¤±è´¥: {e}")
        return None

def export_table_schema(cursor, table_name):
    """å¯¼å‡ºå•ä¸ªè¡¨çš„ç»“æ„"""
    try:
        # è·å–è¡¨çš„åŸºæœ¬ä¿¡æ¯
        cursor.execute(f"""
            SELECT 
                COLUMN_NAME,
                DATA_TYPE,
                CHARACTER_MAXIMUM_LENGTH,
                NUMERIC_PRECISION,
                NUMERIC_SCALE,
                IS_NULLABLE,
                COLUMN_DEFAULT,
                ORDINAL_POSITION
            FROM INFORMATION_SCHEMA.COLUMNS 
            WHERE TABLE_NAME = '{table_name}'
            ORDER BY ORDINAL_POSITION
        """)
        columns = cursor.fetchall()
        
        if not columns:
            return f"-- è¡¨ {table_name} ä¸å­˜åœ¨æˆ–æ²¡æœ‰åˆ—\n"
        
        # è·å–ä¸»é”®ä¿¡æ¯
        cursor.execute(f"""
            SELECT COLUMN_NAME
            FROM INFORMATION_SCHEMA.KEY_COLUMN_USAGE
            WHERE TABLE_NAME = '{table_name}' AND CONSTRAINT_NAME LIKE 'PK_%'
            ORDER BY ORDINAL_POSITION
        """)
        primary_keys = [row[0] for row in cursor.fetchall()]
        
        # è·å–å¤–é”®ä¿¡æ¯
        cursor.execute(f"""
            SELECT 
                kcu.COLUMN_NAME,
                ccu.TABLE_NAME AS REFERENCED_TABLE_NAME,
                ccu.COLUMN_NAME AS REFERENCED_COLUMN_NAME
            FROM INFORMATION_SCHEMA.KEY_COLUMN_USAGE kcu
            INNER JOIN INFORMATION_SCHEMA.REFERENTIAL_CONSTRAINTS rc
                ON kcu.CONSTRAINT_NAME = rc.CONSTRAINT_NAME
            INNER JOIN INFORMATION_SCHEMA.CONSTRAINT_COLUMN_USAGE ccu
                ON rc.UNIQUE_CONSTRAINT_NAME = ccu.CONSTRAINT_NAME
            WHERE kcu.TABLE_NAME = '{table_name}'
        """)
        foreign_keys = cursor.fetchall()
        
        # ç”ŸæˆCREATE TABLEè¯­å¥
        schema_sql = f"-- è¡¨: {table_name}\n"
        schema_sql += f"CREATE TABLE [{table_name}] (\n"
        
        column_definitions = []
        for col in columns:
            col_name = col[0]
            data_type = col[1]
            max_length = col[2]
            precision = col[3]
            scale = col[4]
            is_nullable = col[5]
            default_value = col[6]
            
            # æ„å»ºæ•°æ®ç±»å‹
            if data_type in ['varchar', 'nvarchar', 'char', 'nchar']:
                if max_length == -1:
                    type_def = f"{data_type}(MAX)"
                else:
                    type_def = f"{data_type}({max_length})"
            elif data_type in ['decimal', 'numeric']:
                type_def = f"{data_type}({precision},{scale})"
            else:
                type_def = data_type
            
            # æ„å»ºåˆ—å®šä¹‰
            col_def = f"    [{col_name}] {type_def}"
            
            # æ·»åŠ NOT NULLçº¦æŸ
            if is_nullable == 'NO':
                col_def += " NOT NULL"
            
            # æ·»åŠ é»˜è®¤å€¼
            if default_value:
                col_def += f" DEFAULT {default_value}"
            
            column_definitions.append(col_def)
        
        schema_sql += ",\n".join(column_definitions)
        
        # æ·»åŠ ä¸»é”®çº¦æŸ
        if primary_keys:
            pk_cols = ", ".join([f"[{pk}]" for pk in primary_keys])
            schema_sql += f",\n    PRIMARY KEY ({pk_cols})"
        
        schema_sql += "\n);\n\n"
        
        # æ·»åŠ å¤–é”®çº¦æŸ
        for fk in foreign_keys:
            col_name, ref_table, ref_col = fk
            schema_sql += f"ALTER TABLE [{table_name}] ADD CONSTRAINT FK_{table_name}_{col_name} "
            schema_sql += f"FOREIGN KEY ([{col_name}]) REFERENCES [{ref_table}]([{ref_col}]);\n"
        
        if foreign_keys:
            schema_sql += "\n"
        
        return schema_sql
        
    except Exception as e:
        logger.error(f"âŒ å¯¼å‡ºè¡¨ {table_name} ç»“æ„å¤±è´¥: {e}")
        return f"-- å¯¼å‡ºè¡¨ {table_name} å¤±è´¥: {e}\n"

def export_database_schema(database_name):
    """å¯¼å‡ºæ•´ä¸ªæ•°æ®åº“çš„ç»“æ„"""
    logger.info(f"ğŸ”„ å¼€å§‹å¯¼å‡º {database_name} æ•°æ®åº“ç»“æ„...")
    
    conn = get_connection(database_name)
    if not conn:
        return False
    
    try:
        cursor = conn.cursor()
        
        # è·å–æ‰€æœ‰è¡¨å
        cursor.execute("""
            SELECT TABLE_NAME 
            FROM INFORMATION_SCHEMA.TABLES 
            WHERE TABLE_TYPE = 'BASE TABLE'
            ORDER BY TABLE_NAME
        """)
        tables = [row[0] for row in cursor.fetchall()]
        
        logger.info(f"ğŸ“Š æ‰¾åˆ° {len(tables)} ä¸ªè¡¨")
        
        # ç”Ÿæˆå®Œæ•´çš„schemaæ–‡ä»¶
        schema_content = f"-- {database_name} æ•°æ®åº“ç»“æ„\n"
        schema_content += f"-- å¯¼å‡ºæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
        schema_content += f"-- è¡¨æ•°é‡: {len(tables)}\n\n"
        
        # å¯¼å‡ºæ¯ä¸ªè¡¨çš„ç»“æ„
        for table_name in tables:
            logger.info(f"ğŸ“‹ å¯¼å‡ºè¡¨: {table_name}")
            table_schema = export_table_schema(cursor, table_name)
            schema_content += table_schema
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        filename = f"{database_name}_schema.sql"
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(schema_content)
        
        logger.info(f"âœ… {database_name} æ•°æ®åº“ç»“æ„å·²å¯¼å‡ºåˆ°: {filename}")
        return True
        
    except Exception as e:
        logger.error(f"âŒ å¯¼å‡º {database_name} æ•°æ®åº“ç»“æ„å¤±è´¥: {e}")
        return False
    finally:
        conn.close()

def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹å¯¼å‡ºæ•°æ®åº“ç»“æ„...")
    
    databases = ['cyrg2025', 'cyrgweixin', 'hotdog2030']
    
    for db_name in databases:
        logger.info(f"ğŸ“‹ å¤„ç†æ•°æ®åº“: {db_name}")
        success = export_database_schema(db_name)
        if success:
            logger.info(f"âœ… {db_name} å¯¼å‡ºæˆåŠŸ")
        else:
            logger.error(f"âŒ {db_name} å¯¼å‡ºå¤±è´¥")
        logger.info("-" * 50)
    
    logger.info("ğŸ‰ æ•°æ®åº“ç»“æ„å¯¼å‡ºå®Œæˆï¼")

if __name__ == "__main__":
    main()
